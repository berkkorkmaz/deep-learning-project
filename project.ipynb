{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/berkkorkmaz/deep-learning-project/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1v5ES3t9SlV",
        "outputId": "04969ba9-c493-46e4-fe9f-78787c26a4e2"
      },
      "source": [
        "from google.colab import drive\r\n",
        "import sys\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import os\r\n",
        "import cv2\r\n",
        "from tqdm import tqdm\r\n",
        "import pandas as pd\r\n",
        "import math\r\n",
        "import statistics\r\n",
        "import pickle\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjj0EzX0CYwz"
      },
      "source": [
        "CATEGORIES = [\"Covid-19\", \"Normal\", \"Pneumonia-Bacteria\",  \"Pneumonia-Virus\"]\r\n",
        "DATADIR = \"/content/drive/MyDrive/Colab Notebooks/project/data\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9uPfZT12WDf"
      },
      "source": [
        "CATEGORIES = [\"Covid-19\", \"Normal\", \"Pneumonia-Bacteria\",  \"Pneumonia-Virus\"]\n",
        "\n",
        "IMG_SIZE = 300\n",
        "\n",
        "train_images = os.listdir(os.path.join(DATADIR,\"train\"))\n",
        "test_images = os.listdir(os.path.join(DATADIR,\"test\"))\n",
        "extra_covid_images = os.listdir(os.path.join(DATADIR,\"COVID\"))\n",
        "\n",
        "data_summary = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/project/data/Chest_xray_Corona_dataset_Summary.csv\")\n",
        "data_labels = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/project/data/Chest_xray_Corona_Metadata.csv\")\n",
        "\n",
        "# Arrays for training and test data \n",
        "training_data = []\n",
        "test_data = []\n",
        "\n",
        "def create_dataset(is_training):\n",
        "    data_type = [\"train\"  if is_training else \"test\"][0]\n",
        "    \n",
        "    path = os.path.join(DATADIR, data_type)\n",
        "    \n",
        "    class_num = None  # get the classification for every category index\n",
        "    \n",
        "    for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
        "        for data in range(0, len(data_labels['Label'])):\n",
        "            if img == data_labels['X_ray_image_name'][data] and data_labels['Dataset_type'][data].lower() ==data_type:\n",
        "                if data_labels['Label'][data] == 'Normal':\n",
        "                    class_num = CATEGORIES.index('Normal')\n",
        "                elif data_labels['Label'][data] == 'Pnemonia':\n",
        "                    pnemonia_category_1 = data_labels['Label_1_Virus_category'][data]\n",
        "                    pnemonia_category_2 = data_labels['Label_2_Virus_category'][data]\n",
        "                    if pnemonia_category_1 == 'bacteria':\n",
        "                        class_num = CATEGORIES.index('Pneumonia-Bacteria')\n",
        "                    if pnemonia_category_1 == 'Virus':\n",
        "                        if pnemonia_category_2 == 'COVID-19':\n",
        "                            class_num = CATEGORIES.index('Covid-19')\n",
        "                        else:\n",
        "                            class_num = CATEGORIES.index('Pneumonia-Virus')\n",
        "        try:\n",
        "            # Read the image from the folder by using OpenCv and convert to Grayscale\n",
        "            img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)\n",
        "            # Resize the images for normalization\n",
        "            extracted_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "            # Add extracted image to training or test arrays\n",
        "            if data_type == \"train\":\n",
        "                training_data.append([extracted_array, class_num])  # add this to our training_data\n",
        "            else:\n",
        "                test_data.append([extracted_array, class_num])  # add this to our test_data\n",
        "        except Exception as e:  # in the interest in keeping the output clean...\n",
        "            pass\n",
        "\n",
        "create_dataset(True)  # Run the function for training data\n",
        "create_dataset(False) # Run the function for test data\n",
        "\n",
        "def create_extra_dataset(distribution=0.8):\n",
        "    \n",
        "    path = os.path.join(DATADIR, \"COVID\")\n",
        "    class_num = CATEGORIES.index('Covid-19')\n",
        "    \n",
        "    training_images_number = int(distribution*len(os.listdir(path)))\n",
        "    test_images_number = len(os.listdir(path)) - training_images_number\n",
        "    \n",
        "    image_index = 0    \n",
        "    for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
        "        image_index += 1\n",
        "        try:\n",
        "            # Read the image from the folder by using OpenCv and convert to Grayscale\n",
        "            img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)\n",
        "            # Resize the images for normalization\n",
        "            extracted_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "            # Add extracted image to training or test arrays\n",
        "            if image_index <= training_images_number:\n",
        "                training_data.append([extracted_array, class_num])  # add this to our training_data\n",
        "            else:\n",
        "                test_data.append([extracted_array, class_num])  # add this to our test_data\n",
        "        except Exception as e:  # in the interest in keeping the output clean...\n",
        "            pass\n",
        "\n",
        "create_extra_dataset(distribution=0.8) # Run the function for extra Covid dataset for both training and test\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bfbNPF92WD1"
      },
      "source": [
        "training_covid19_count = 0\n",
        "training_normal_count = 0\n",
        "training_pneumonia_virus = 0\n",
        "training_pneumonia_bacteria = 0\n",
        "\n",
        "for data_count in training_data:\n",
        "    if data_count[1] == CATEGORIES.index('Covid-19'):\n",
        "        training_covid19_count += 1\n",
        "    elif data_count[1] == CATEGORIES.index('Normal'):\n",
        "        training_normal_count += 1\n",
        "    elif data_count[1] == CATEGORIES.index('Pneumonia-Virus'):\n",
        "        training_pneumonia_virus += 1\n",
        "    elif data_count[1] == CATEGORIES.index('Pneumonia-Bacteria'):\n",
        "        training_pneumonia_bacteria += 1\n",
        "        \n",
        "print('Training ====> Covid-19: ', training_covid19_count,\"---\",'Normal: ', training_normal_count,\"---\", \n",
        "      'Pneumonia_Virus: ', training_pneumonia_virus,\"---\", 'Pneumonia_Bacteria: ', training_pneumonia_bacteria)\n",
        "\n",
        "\n",
        "test_covid19_count = 0\n",
        "test_normal_count = 0\n",
        "test_pneumonia_virus = 0\n",
        "test_pneumonia_bacteria = 0\n",
        "\n",
        "for data_count in test_data:\n",
        "    if data_count[1] == CATEGORIES.index('Covid-19'):\n",
        "        test_covid19_count += 1\n",
        "    elif data_count[1] == CATEGORIES.index('Normal'):\n",
        "        test_normal_count += 1\n",
        "    elif data_count[1] == CATEGORIES.index('Pneumonia-Virus'):\n",
        "        test_pneumonia_virus += 1\n",
        "    elif data_count[1] == CATEGORIES.index('Pneumonia-Bacteria'):\n",
        "        test_pneumonia_bacteria += 1\n",
        "        \n",
        "print('Test ====> Covid-19: ', test_covid19_count,\"---\", 'Normal: ', test_normal_count,\"---\", \n",
        "      'Pneumonia_Virus: ', test_pneumonia_virus,\"---\", 'Pneumonia_Bacteria: ', test_pneumonia_bacteria)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-CadtrW2WD3"
      },
      "source": [
        "# importing the random module\n",
        "import random\n",
        "\n",
        "covid19_image, normal_image, pneumonia_virus_image, pneumonia_bacteria_image = 0, 0, 0, 0\n",
        "while True:\n",
        "    data = random.randint(0,len(training_data))\n",
        "    if covid19_image == 0:\n",
        "        if training_data[data][1] == CATEGORIES.index('Covid-19'):\n",
        "            covid19_image = data\n",
        "    if normal_image == 0:\n",
        "        if training_data[data][1] == CATEGORIES.index('Normal'):\n",
        "            normal_image = data\n",
        "        if training_data[data][1] == CATEGORIES.index('Pneumonia-Virus'):\n",
        "            pneumonia_virus_image = data\n",
        "    if pneumonia_bacteria_image == 0:\n",
        "        if training_data[data][1] == CATEGORIES.index('Pneumonia-Bacteria'):\n",
        "            pneumonia_bacteria_image = data\n",
        "    if min(covid19_image, normal_image, pneumonia_virus_image, pneumonia_bacteria_image)!= 0:\n",
        "        break\n",
        "\n",
        "plt.figure(figsize=(15, 15));\n",
        "\n",
        "### Plotting the Normal Patient X-ray Chest Image\n",
        "plt.subplot(2, 2, 1); plt.title('Normal Chest X-ray ',fontsize=20);\n",
        "plt.imshow(training_data[normal_image][0], cmap='gray')  # graph it\n",
        "\n",
        "### Plotting the Normal Patient X-ray Chest Image\n",
        "plt.subplot(2, 2, 2); plt.title(\"Covid-19 Patient Chest X-ray\",fontsize=20);\n",
        "plt.imshow(training_data[covid19_image][0], cmap='gray')  # graph it\n",
        "\n",
        "### Plotting the Normal Patient X-ray Chest Image\n",
        "plt.subplot(2, 2, 3); plt.title('Virus infected Patient Chest X-ray ',fontsize=20);\n",
        "plt.imshow(training_data[pneumonia_virus_image][0], cmap='gray')  # graph it\n",
        "\n",
        "### Plotting the Normal Patient X-ray Chest Image\n",
        "plt.subplot(2, 2, 4); plt.title(\"Bacteria infected Chest X-ray\",fontsize=20);\n",
        "plt.imshow(training_data[pneumonia_bacteria_image][0], cmap='gray')  # graph it\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwDd5EV-2WD4"
      },
      "source": [
        "# Data is shuffled randomly\n",
        "random.shuffle(training_data)\n",
        "random.shuffle(test_data)\n",
        "# Arrays for training and test data for both features and labels\n",
        "training_X = [];training_y = [];test_X = [];test_y = []\n",
        "for features,label in training_data:\n",
        "    training_X.append(features)\n",
        "    training_y.append(label)\n",
        "\n",
        "for features,label in test_data:\n",
        "    test_X.append(features)\n",
        "    test_y.append(label)\n",
        "    \n",
        "# Arrays are converted to numpy arrays to be used\n",
        "training_y = np.array(training_y)\n",
        "test_y = np.array(test_y)\n",
        "\n",
        "training_X = np.array(training_X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "test_X = np.array(test_X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8tDrt5sy30-"
      },
      "source": [
        "import pickle\r\n",
        "\r\n",
        "pickle_out = open(\"/content/drive/MyDrive/Colab Notebooks/project/training_X.pickle\",\"wb\")\r\n",
        "pickle.dump(training_X, pickle_out)\r\n",
        "pickle_out.close()\r\n",
        "\r\n",
        "pickle_out = open(\"/content/drive/MyDrive/Colab Notebooks/project/training_y.pickle\",\"wb\")\r\n",
        "pickle.dump(training_y, pickle_out)\r\n",
        "pickle_out.close()\r\n",
        "\r\n",
        "pickle_out = open(\"/content/drive/MyDrive/Colab Notebooks/project/test_y.pickle\",\"wb\")\r\n",
        "pickle.dump(test_y, pickle_out)\r\n",
        "pickle_out.close()\r\n",
        "\r\n",
        "pickle_out = open(\"/content/drive/MyDrive/Colab Notebooks/project/test_X.pickle\",\"wb\")\r\n",
        "pickle.dump(test_X, pickle_out)\r\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0rSCRK4-x3S"
      },
      "source": [
        "import pickle\r\n",
        "\r\n",
        "IMG_SIZE = 300\r\n",
        "\r\n",
        "pickle_in = open(\"/content/drive/MyDrive/Colab Notebooks/project/training_X.pickle\",\"rb\")\r\n",
        "trn_X = pickle.load(pickle_in)\r\n",
        "pickle_in.close()\r\n",
        "\r\n",
        "pickle_in = open(\"/content/drive/MyDrive/Colab Notebooks/project/training_y.pickle\",\"rb\")\r\n",
        "trn_y = pickle.load(pickle_in)\r\n",
        "pickle_in.close()\r\n",
        "\r\n",
        "pickle_in = open(\"/content/drive/MyDrive/Colab Notebooks/project/test_X.pickle\",\"rb\")\r\n",
        "tst_X = pickle.load(pickle_in)\r\n",
        "pickle_in.close()\r\n",
        "pickle_in = open(\"/content/drive/MyDrive/Colab Notebooks/project/test_y.pickle\",\"rb\")\r\n",
        "tst_y = pickle.load(pickle_in)\r\n",
        "pickle_in.close()\r\n",
        "\r\n",
        "trn_X = trn_X/255.0\r\n",
        "\r\n",
        "trn_X = np.array(trn_X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\r\n",
        "\r\n",
        "trn_y = np.array(trn_y)\r\n",
        "\r\n",
        "tst_X = tst_X/255.0\r\n",
        "\r\n",
        "tst_X = np.array(tst_X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\r\n",
        "\r\n",
        "tst_y = np.array(tst_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAkyvpePHFdw"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\r\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\r\n",
        "from tensorflow.keras.callbacks import TensorBoard\r\n",
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "\r\n",
        "encoder = LabelBinarizer()\r\n",
        "trn_y_t = encoder.fit_transform(trn_y)\r\n",
        "tst_y_t = encoder.transform(tst_y)\r\n",
        "\r\n",
        "input_shape=trn_X.shape[1:]\r\n",
        "\r\n",
        "\r\n",
        "model=Sequential()\r\n",
        "\r\n",
        "model.add(Conv2D(64,kernel_size=(3,3),activation=\"relu\",input_shape=input_shape))\r\n",
        "\r\n",
        "model.add(Conv2D(64,(3,3),activation=\"relu\"))\r\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Conv2D(64,(3,3),activation=\"relu\"))\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Conv2D(128,(3,3),activation=\"relu\"))\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(64,activation=\"relu\"))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "\r\n",
        "model.add(Dense(4))\r\n",
        "model.add(Activation('softmax'))\r\n",
        "model.compile(loss='categorical_crossentropy',\r\n",
        "                          optimizer='adam',\r\n",
        "                          metrics=['accuracy'],\r\n",
        "                          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB0XRy9vusy0",
        "outputId": "42539c82-d1d2-44fa-f11b-bb239ae2189c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 298, 298, 64)      640       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 296, 296, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 148, 148, 64)      0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 148, 148, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 146, 146, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 73, 73, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 71, 71, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 35, 35, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 156800)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                10035264  \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 260       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 4)                 0         \n",
            "=================================================================\n",
            "Total params: 10,183,876\n",
            "Trainable params: 10,183,876\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4eMSg52OFV7",
        "outputId": "184d1797-67fd-4cd9-9eb7-836dc2442dcf"
      },
      "source": [
        "model.fit(trn_X, \r\n",
        "          trn_y_t,\r\n",
        "          batch_size=32,\r\n",
        "          epochs=5,\r\n",
        "          validation_data=(tst_X, tst_y_t))\r\n",
        "\r\n",
        "model.save('cnn1.model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "196/196 [==============================] - 4702s 24s/step - loss: 1.3060 - accuracy: 0.4240 - val_loss: 0.7694 - val_accuracy: 0.6736\n",
            "Epoch 2/5\n",
            "196/196 [==============================] - 4645s 24s/step - loss: 0.7790 - accuracy: 0.6604 - val_loss: 0.7995 - val_accuracy: 0.6458\n",
            "Epoch 3/5\n",
            "196/196 [==============================] - 4639s 24s/step - loss: 0.6504 - accuracy: 0.7116 - val_loss: 0.9204 - val_accuracy: 0.6910\n",
            "Epoch 4/5\n",
            "196/196 [==============================] - 4558s 23s/step - loss: 0.6250 - accuracy: 0.7311 - val_loss: 0.9550 - val_accuracy: 0.7049\n",
            "Epoch 5/5\n",
            "196/196 [==============================] - 4640s 24s/step - loss: 0.5820 - accuracy: 0.7447 - val_loss: 1.0790 - val_accuracy: 0.7280\n",
            "INFO:tensorflow:Assets written to: cnn1.model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS77hmbANJyI"
      },
      "source": [
        "\r\n",
        "score = model.evaluate(x_test, y_test, verbose=0) \r\n",
        "score[1]\r\n",
        "\r\n",
        "# Actual accuracy calculated manually:\r\n",
        "import numpy as np\r\n",
        "y_pred = model.predict(x_test)\r\n",
        "acc = sum([np.argmax(y_test[i])==np.argmax(y_pred[i]) for i in range(10000)])/10000\r\n",
        "acc\r\n",
        "# 0.98780000000000001\r\n",
        "\r\n",
        "score[1]==acc\r\n",
        "# False    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}